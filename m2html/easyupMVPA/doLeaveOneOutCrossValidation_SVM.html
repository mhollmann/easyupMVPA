<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of doLeaveOneOutCrossValidation_SVM</title>
  <meta name="keywords" content="doLeaveOneOutCrossValidation_SVM">
  <meta name="description" content="Implements a Leave One Out Cross Validation (LOOCV) using a Support Vector Machine Classifier (parallel execution).">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../index.html">Home</a> &gt;  <a href="index.html">easyupMVPA</a> &gt; doLeaveOneOutCrossValidation_SVM.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../index.html"><img alt="<" border="0" src="../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for easyupMVPA&nbsp;<img alt=">" border="0" src="../right.png"></a></td></tr></table>-->

<h1>doLeaveOneOutCrossValidation_SVM
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>Implements a Leave One Out Cross Validation (LOOCV) using a Support Vector Machine Classifier (parallel execution).</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>function [dataset, resultStruct, avgWeights] = doLeaveOneOutCrossValidation_SVM(dataset, dataSplitter, svmType, kernelMode, costParam, paramStruct) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Implements a Leave One Out Cross Validation (LOOCV) using a Support Vector Machine Classifier (parallel execution).

 Author: Maurice Hollmann
 Date  : 08/10

 Description:

   [dataset, resultStruct, avgWeights] = doLeaveOneOutCrossValidation_SVM(dataset, dataSplitter, svmType, kernelMode, costParam, [paramStruct])

   This highlevel function does the Leave One Out Cross Validation (LOOCV) of a complete dataset(DS) using a Support Vector Machine.
   LOOCV means a repeated classification in the dataset to get a general performance measure.
   Which samples are used in every repetition as training and testing set is described in the given dataSplitter-struct.

   For a &quot;oneSampleOut&quot;-splitter LOOCV means that for every single sample in DS the DS without this sample is trained and the test is 
   done on the excluded sample. This means the classifier is trained n times for n samples, which may be very time consuming.

   In every new training the weights used in the model are saved and the function returns the average weights of all single models trained.

   Explanation of resultStruct fields:
   Accuracy:    Percentual value of correct predictions (correct * 100 / nmbSamples)
   Sensitivity: TP/TP+FN (Proportion of true positives to all positives)
   Specificity: TN/TN+FP (Proportion of true negatives to all negatives)

   If possible, the function executes parallelized depending on settings defined via easyupMVPA_init().


 Parameters:
   dataset        - The dataset to work on  (all samples are included in LOOCV)
   dataSplitter   - describes the splitting of the data in LOOCV
   svmType        - Types:
                     ['classification', 'regression_epsilon', 'regression_nu']
   kernelMode     - Kernels: ['linear', 'polynomial', 'radial', 'sigmoid']
   costParam      - The slack variable C in SVM (range 0 to 1  0 = low cost, 1 = highest costs). 
                    It defines the costs for misclassification (How strongly are outliers punished?).
   paramStruct    - [optional] - i.e. {&quot;degree&quot;, 3}


 Returns:
   dataset        - the datset that has been the input 
   resultStruct   - The struct holding the classification results: 
                    resultStruct.nmbTests     (the number of samples tested for this result)
                    resultStruct.accuracy     (percentual value of correct predictions (correct * 100 / nmbSamples))
                    resultStruct.sensitivity  (TP/TP+FN = Proportion of true positives to all positives)
                    resultStruct.specificity  (TN/TN+FP = Proportion of true negatives to all negatives)
                    resultStruct.TP           (True positives = all correct predicted in class 1)
                    resultStruct.TN           (True negatives = all correct predicted in class 2)
                    resultStruct.FP           (False positives = all incorrect predicted in class 1)
                    resultStruct.FN           (False negatives = all incorrect predicted in class 2)
   avgWeights    - a 3D or 1D map containing the average weights used in the LOOCV (See Description of this function)


 Comments:</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="easyupMVPA_getGlobals.html" class="code" title="function [propertyValue] = easyupMVPA_getGlobals(propertyName)">easyupMVPA_getGlobals</a>	Returns values for global properties in the toolbox.</li><li><a href="selectFeaturesBySelectionMap.html" class="code" title="function [dataset, data2D] = selectFeaturesBySelectionMap(dataset)">selectFeaturesBySelectionMap</a>	Apply a featureSelection map that is stored in a dataset to this dataset.</li><li><a href="setDataset_featureSelectionMap_ByMatrix.html" class="code" title="function [dataset] = setDataset_featureSelectionMap_ByMatrix(dataset, mapMatrix)">setDataset_featureSelectionMap_ByMatrix</a>	Set the featureSelectionMap (1D or 3D) field of a dataset by a given matrix.</li><li><a href="splitDataset.html" class="code" title="function [dataset1, dataset2] = splitDataset(dataset, vectorDS1, vectorDS2)">splitDataset</a>	Splits a dataset by selecting the elements defined by given vectors for the two result datasets.</li></ul>
This function is called by:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="doRecursiveFeatureElemination_SVM_nestedLOOCV.html" class="code" title="function [dataset, resultStruct, avg_rfe_weightMap, avg_rfe_featureSelectionMap, rfe_weightMaps, rfe_featureSelectionMaps] = doRecursiveFeatureElemination_SVM_nestedLOOCV(dataset, nmbIterations, thresholdPercentOfFeaturesOut, nmbSplitsLOOCV, dataSplitter, kernelMode, costParam, paramStruct)">doRecursiveFeatureElemination_SVM_nestedLOOCV</a>	! DEPRECATED ! Recursively removes features according to SVM classification weights from LOOCV.</li><li><a href="doRecursiveFeatureElemination_bootStrap_SVM.html" class="code" title="function [dataset, resultStruct] = doRecursiveFeatureElemination_bootStrap_SVM(dataset, nmbBootSteps)">doRecursiveFeatureElemination_bootStrap_SVM</a>	[DO NOT USE: UNDER DEVELOPEMENT!] Recursively removes features according to SVM classification weights obtained by bootstrapping.</li></ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="#_sub1" class="code">function [ds, maskedData2D] = member_getMasked2DData_from4D(ds)</a></li><li><a href="#_sub2" class="code">function [ds, maskedData2D] = member_getMasked2DData_from2D(ds)</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre>0001 <span class="comment">% Implements a Leave One Out Cross Validation (LOOCV) using a Support Vector Machine Classifier (parallel execution).</span>
0002 <span class="comment">%</span>
0003 <span class="comment">% Author: Maurice Hollmann</span>
0004 <span class="comment">% Date  : 08/10</span>
0005 <span class="comment">%</span>
0006 <span class="comment">% Description:</span>
0007 <span class="comment">%</span>
0008 <span class="comment">%   [dataset, resultStruct, avgWeights] = doLeaveOneOutCrossValidation_SVM(dataset, dataSplitter, svmType, kernelMode, costParam, [paramStruct])</span>
0009 <span class="comment">%</span>
0010 <span class="comment">%   This highlevel function does the Leave One Out Cross Validation (LOOCV) of a complete dataset(DS) using a Support Vector Machine.</span>
0011 <span class="comment">%   LOOCV means a repeated classification in the dataset to get a general performance measure.</span>
0012 <span class="comment">%   Which samples are used in every repetition as training and testing set is described in the given dataSplitter-struct.</span>
0013 <span class="comment">%</span>
0014 <span class="comment">%   For a &quot;oneSampleOut&quot;-splitter LOOCV means that for every single sample in DS the DS without this sample is trained and the test is</span>
0015 <span class="comment">%   done on the excluded sample. This means the classifier is trained n times for n samples, which may be very time consuming.</span>
0016 <span class="comment">%</span>
0017 <span class="comment">%   In every new training the weights used in the model are saved and the function returns the average weights of all single models trained.</span>
0018 <span class="comment">%</span>
0019 <span class="comment">%   Explanation of resultStruct fields:</span>
0020 <span class="comment">%   Accuracy:    Percentual value of correct predictions (correct * 100 / nmbSamples)</span>
0021 <span class="comment">%   Sensitivity: TP/TP+FN (Proportion of true positives to all positives)</span>
0022 <span class="comment">%   Specificity: TN/TN+FP (Proportion of true negatives to all negatives)</span>
0023 <span class="comment">%</span>
0024 <span class="comment">%   If possible, the function executes parallelized depending on settings defined via easyupMVPA_init().</span>
0025 <span class="comment">%</span>
0026 <span class="comment">%</span>
0027 <span class="comment">% Parameters:</span>
0028 <span class="comment">%   dataset        - The dataset to work on  (all samples are included in LOOCV)</span>
0029 <span class="comment">%   dataSplitter   - describes the splitting of the data in LOOCV</span>
0030 <span class="comment">%   svmType        - Types:</span>
0031 <span class="comment">%                     ['classification', 'regression_epsilon', 'regression_nu']</span>
0032 <span class="comment">%   kernelMode     - Kernels: ['linear', 'polynomial', 'radial', 'sigmoid']</span>
0033 <span class="comment">%   costParam      - The slack variable C in SVM (range 0 to 1  0 = low cost, 1 = highest costs).</span>
0034 <span class="comment">%                    It defines the costs for misclassification (How strongly are outliers punished?).</span>
0035 <span class="comment">%   paramStruct    - [optional] - i.e. {&quot;degree&quot;, 3}</span>
0036 <span class="comment">%</span>
0037 <span class="comment">%</span>
0038 <span class="comment">% Returns:</span>
0039 <span class="comment">%   dataset        - the datset that has been the input</span>
0040 <span class="comment">%   resultStruct   - The struct holding the classification results:</span>
0041 <span class="comment">%                    resultStruct.nmbTests     (the number of samples tested for this result)</span>
0042 <span class="comment">%                    resultStruct.accuracy     (percentual value of correct predictions (correct * 100 / nmbSamples))</span>
0043 <span class="comment">%                    resultStruct.sensitivity  (TP/TP+FN = Proportion of true positives to all positives)</span>
0044 <span class="comment">%                    resultStruct.specificity  (TN/TN+FP = Proportion of true negatives to all negatives)</span>
0045 <span class="comment">%                    resultStruct.TP           (True positives = all correct predicted in class 1)</span>
0046 <span class="comment">%                    resultStruct.TN           (True negatives = all correct predicted in class 2)</span>
0047 <span class="comment">%                    resultStruct.FP           (False positives = all incorrect predicted in class 1)</span>
0048 <span class="comment">%                    resultStruct.FN           (False negatives = all incorrect predicted in class 2)</span>
0049 <span class="comment">%   avgWeights    - a 3D or 1D map containing the average weights used in the LOOCV (See Description of this function)</span>
0050 <span class="comment">%</span>
0051 <span class="comment">%</span>
0052 <span class="comment">% Comments:</span>
0053 <span class="comment">%</span>
0054 <a name="_sub0" href="#_subfunctions" class="code">function [dataset, resultStruct, avgWeights] = doLeaveOneOutCrossValidation_SVM(dataset, dataSplitter, svmType, kernelMode, costParam, paramStruct)</a>
0055  
0056 
0057   <span class="keyword">if</span>( ~exist(<span class="string">'dataset'</span>,<span class="string">'var'</span>) || ~exist(<span class="string">'dataSplitter'</span>,<span class="string">'var'</span>) || ~exist(<span class="string">'svmType'</span>,<span class="string">'var'</span>) || ~exist(<span class="string">'kernelMode'</span>,<span class="string">'var'</span>) || ~exist(<span class="string">'costParam'</span>,<span class="string">'var'</span>)) 
0058     error(<span class="string">'Usage of doLeaveOneOutCrossValidation_SVM: [dataset, classificationResult] = doLeaveOneOutCrossValidation_SVM(dataset, dataSplitter, svmType - [classification, regression_epsilon, regression_nu], kernelMode - [linear, polynomial, radial, sigmoid] , costParam [0-1], paramStruct [optional - i.e. {&quot;degree&quot;, 3}])'</span>);
0059   <span class="keyword">end</span>
0060   
0061   <span class="comment">%extractt the SVM parameter values from paramStruct</span>
0062   <span class="keyword">if</span>( ~exist(<span class="string">'paramStruct'</span>,<span class="string">'var'</span>))
0063     [paramStructIsValid, svmParamInfoStruct, cmdString] = getSVMParamInfo(svmType, kernelMode, costParam, {});
0064   <span class="keyword">else</span>
0065     [paramStructIsValid, svmParamInfoStruct, cmdString] = getSVMParamInfo(svmType, kernelMode, costParam, paramStruct);
0066   <span class="keyword">end</span>
0067   <span class="keyword">if</span>( ~paramStructIsValid)
0068     error(<span class="string">'Usage of doLeaveOneOutCrossValidation_SVM: [dataset, classificationResult] = doLeaveOneOutCrossValidation_SVM(dataset, dataSplitter, svmType - [classification, regression_epsilon, regression_nu], kernelMode - [linear, polynomial, radial, sigmoid] , costParam [0-1], paramStruct [optional - i.e. {&quot;degree&quot;, 3}])'</span>);
0069   <span class="keyword">end</span>
0070   
0071  
0072   
0073   <span class="comment">%use quiet mode (no outputs)</span>
0074   cmdString = [cmdString, <span class="string">' -q '</span>];
0075   
0076    <span class="keyword">if</span>(dataset.is4D)
0077      sizeData   = size(dataset.data);
0078      avgWeights = zeros(sizeData(1),sizeData(2),sizeData(3),1);
0079      tmpWeightsSize = [sizeData(1),sizeData(2),sizeData(3),1];
0080    <span class="keyword">elseif</span>(dataset.is2D)
0081      sizeData   = size(dataset.data);
0082      avgWeights = zeros(sizeData(1),1);
0083      tmpWeightsSize = [sizeData(1),1];
0084    <span class="keyword">else</span>
0085     error(<span class="string">'LOOCV: Please check the dataset: field &quot;type&quot; is not defined!'</span>);
0086    <span class="keyword">end</span>
0087    
0088    nmbSamples = length(dataset.chunks);
0089    
0090    nmbCorrect    = 0;
0091    
0092    nmbTruePosAll    = 0;
0093    nmbTrueNegAll    = 0;
0094    nmbFalsePosAll   = 0;
0095    nmbFalseNegAll   = 0; 
0096    
0097    <span class="comment">%extract the number of splits that are used</span>
0098    nmbSplits = size(dataSplitter.splitMatrix,1);
0099    nmbTests  = numel(find(dataSplitter.splitMatrix(:)==1));
0100    
0101    <span class="comment">%variable to store predicted labels</span>
0102    predictedLabels = {};
0103    
0104    localQuietMode = <a href="easyupMVPA_getGlobals.html" class="code" title="function [propertyValue] = easyupMVPA_getGlobals(propertyName)">easyupMVPA_getGlobals</a>(<span class="string">'quietMode'</span>);
0105    
0106    <span class="keyword">if</span>(~localQuietMode)
0107      disp([<span class="string">'Running Leave One Out Cross Validation with command string: '</span>,cmdString,<span class="string">' ...'</span>]);
0108      <span class="comment">% create a progress display that works also for parallel loops</span>
0109      <span class="keyword">if</span>(nmbSplits &lt;50)
0110        disp([<span class="string">'0%'</span>, num2str(repmat(<span class="string">' '</span>,1,nmbSplits-1)),<span class="string">'100%'</span>]);
0111        progressIndices = [1 1:nmbSplits];
0112      <span class="keyword">else</span>
0113        disp([<span class="string">'0%'</span>, num2str(repmat(<span class="string">' '</span>,1,50)),<span class="string">'100%'</span>]);
0114        <span class="comment">%create a vector with floored indicees for repetitions</span>
0115        progressIndices = [1 1:nmbSplits];
0116        progressIndices = floor(progressIndices*(50/nmbSplits));
0117      <span class="keyword">end</span>
0118      fprintf(<span class="string">'    '</span>);
0119    <span class="keyword">end</span>
0120 
0121    nmbTests = 0;
0122    
0123    splitMatrix = dataSplitter.splitMatrix;
0124    
0125    parfor i=1:nmbSplits
0126      
0127      trainData2D = [];
0128      testData2D  = [];  
0129      
0130      <span class="comment">%at first split the dataset according to given splitting</span>
0131      ds1Indices = splitMatrix(i,:) == 1; <span class="comment">%test data</span>
0132      ds2Indices = splitMatrix(i,:) == 2; <span class="comment">%train data</span>
0133 
0134 
0135      [ds1, ds2] = <a href="splitDataset.html" class="code" title="function [dataset1, dataset2] = splitDataset(dataset, vectorDS1, vectorDS2)">splitDataset</a>(dataset, ds1Indices, ds2Indices );     
0136      
0137      <span class="keyword">if</span>(dataset.is4D)
0138        [ds2, trainData2D] = <a href="#_sub1" class="code" title="subfunction [ds, maskedData2D] = member_getMasked2DData_from4D(ds)">member_getMasked2DData_from4D</a>(ds2);
0139      <span class="keyword">elseif</span>(dataset.is2D)
0140        [ds2, trainData2D] = <a href="#_sub2" class="code" title="subfunction [ds, maskedData2D] = member_getMasked2DData_from2D(ds)">member_getMasked2DData_from2D</a>(ds2);
0141      <span class="keyword">end</span>
0142      
0143      <span class="comment">%train on all samples with one left out</span>
0144      svmModel  = svmtrain(double(ds2.classIDs)', trainData2D, cmdString);
0145      
0146      <span class="comment">%extract the weights</span>
0147      weights = svmModel.SVs' * svmModel.sv_coef;
0148      
0149      tmpWeights = zeros(tmpWeightsSize);
0150      
0151      <span class="keyword">if</span>(dataset.is4D)
0152        
0153        tmpWeights(ds2.featureSelectionMap &gt;0) = weights;
0154        avgWeights = avgWeights + tmpWeights*(1/nmbSamples);
0155        
0156        <span class="comment">%select the data for the testset</span>
0157        [ds1, testData2D] = <a href="#_sub1" class="code" title="subfunction [ds, maskedData2D] = member_getMasked2DData_from4D(ds)">member_getMasked2DData_from4D</a>(ds1);
0158        
0159      <span class="keyword">elseif</span>(dataset.is2D)
0160        
0161        tmpWeights(ds2.featureSelectionMap &gt;0) = weights;
0162        avgWeights = avgWeights + tmpWeights*(1/nmbSamples);
0163        
0164         <span class="comment">%select the data for the testset</span>
0165        [ds1, testData2D] = <a href="#_sub2" class="code" title="subfunction [ds, maskedData2D] = member_getMasked2DData_from2D(ds)">member_getMasked2DData_from2D</a>(ds1);
0166        
0167      <span class="keyword">end</span>
0168      
0169      <span class="comment">%predict the class ID of the test data</span>
0170      <span class="comment">%check if the model was trained with probability estimates</span>
0171      <span class="keyword">if</span>(~isempty(svmModel.ProbA) &amp;&amp; ~isempty(svmModel.ProbB))
0172        [predicted_labels, accuracy, probEst] = svmpredict_modifiedMH(double(ds1.classIDs)', testData2D, svmModel, <span class="string">'-b 1'</span>);
0173        <span class="comment">%disp(probEstimatesVector);</span>
0174      <span class="keyword">else</span>
0175        [predicted_labels, accuracy, probEst] = svmpredict_modifiedMH(double(ds1.classIDs)', testData2D, svmModel); 
0176      <span class="keyword">end</span>
0177      
0178      <span class="comment">%remember predicted labels</span>
0179      predictedLabels(i).predLabels = predicted_labels;
0180      
0181      <span class="keyword">if</span>(strcmp(svmType, <span class="string">'classification'</span>))
0182 
0183        cVec = predicted_labels' == ds1.classIDs;
0184 
0185        nmbTruePos  = sum(cVec(ds1.classIDs==1));
0186        nmbTrueNeg  = sum(cVec(ds1.classIDs==0));
0187        nmbFalsePos = sum(ds1.classIDs) - sum(predicted_labels);
0188        <span class="keyword">if</span>(nmbFalsePos &lt; 0)
0189          nmbFalsePos = abs(nmbFalsePos);
0190        <span class="keyword">else</span>
0191          nmbFalsePos = 0;
0192        <span class="keyword">end</span>
0193        nmbFalseNeg = length(ds1.classIDs) - nmbTrueNeg - nmbFalsePos - nmbTruePos;
0194 
0195        nmbCorrect = nmbCorrect+nmbTruePos+nmbTrueNeg;
0196 
0197        nmbTruePosAll    = nmbTruePosAll+nmbTruePos;
0198        nmbTrueNegAll    = nmbTrueNegAll+nmbTrueNeg;
0199        nmbFalsePosAll   = nmbFalsePosAll+nmbFalsePos;
0200        nmbFalseNegAll   = nmbFalseNegAll+nmbFalseNeg; 
0201        
0202      <span class="keyword">end</span>
0203      
0204      
0205      nmbTests         = nmbTests+length(ds1.classIDs);
0206 
0207      <span class="keyword">if</span>(~localQuietMode)
0208        <span class="keyword">if</span>(progressIndices(i)&lt;progressIndices(i+1))
0209          fprintf(<span class="string">'\b\b*'</span>);
0210          disp([<span class="string">''</span> 0]);
0211        <span class="keyword">end</span>
0212      <span class="keyword">end</span>
0213 
0214    <span class="keyword">end</span> <span class="comment">% end parfor</span>
0215    
0216    <span class="keyword">if</span>(~localQuietMode)
0217      fprintf(<span class="string">'\n'</span>);
0218    <span class="keyword">end</span>
0219    
0220    predLabelsVec = [];
0221    <span class="keyword">for</span> i=1:length(predictedLabels)
0222      <span class="comment">%sorry it is growing but hard to avoid</span>
0223      predLabelsVec = horzcat(predLabelsVec, predictedLabels(i).predLabels);
0224    <span class="keyword">end</span>
0225    
0226    <span class="keyword">if</span>(strcmp(svmType, <span class="string">'classification'</span>))
0227 
0228      accuracy    = nmbCorrect/nmbTests*100;
0229      sensitivity = nmbTruePosAll/(nmbTruePosAll+nmbFalseNegAll); 
0230      specificity = nmbTrueNegAll/(nmbTrueNegAll+nmbFalsePosAll);
0231 
0232      resultStruct             = {};
0233      resultStruct.nmbTests    = nmbTests;
0234      resultStruct.accuracy    = accuracy;
0235      resultStruct.sensitivity = sensitivity;
0236      resultStruct.specificity = specificity;
0237      resultStruct.TP          = nmbTruePosAll;
0238      resultStruct.TN          = nmbTrueNegAll;
0239      resultStruct.FP          = nmbFalsePosAll;
0240      resultStruct.FN          = nmbFalseNegAll;
0241      resultStruct.predictedClassIDs = predLabelsVec;
0242      
0243    <span class="keyword">else</span> <span class="comment">%must be regression</span>
0244      
0245      resultStruct             = {};
0246      resultStruct.nmbTests    = nmbTests;
0247      resultStruct.accuracy    = NaN;
0248      resultStruct.sensitivity = NaN;
0249      resultStruct.specificity = NaN;
0250      resultStruct.TP          = NaN;
0251      resultStruct.TN          = NaN;
0252      resultStruct.FP          = NaN;
0253      resultStruct.FN          = NaN;
0254      resultStruct.predictedClassIDs = predLabelsVec;
0255      
0256    <span class="keyword">end</span>
0257    
0258 <span class="keyword">end</span>
0259 
0260 
0261 
0262 <a name="_sub1" href="#_subfunctions" class="code">function [ds, maskedData2D] = member_getMasked2DData_from4D(ds)</a>
0263   sizeMaskedData2D = size(ds.data);
0264      
0265   <span class="comment">%get the data as 2D array by using the 3D mask or selection map</span>
0266   <span class="comment">%the function selectFeaturesBySelectionMap sets the field dataset.featureSelectionMap3D</span>
0267   <span class="keyword">if</span>(isfield(ds,<span class="string">'featureSelectionMap'</span>) &amp;&amp; ~isempty(ds.featureSelectionMap))
0268     [ds, maskedData2D] = <a href="selectFeaturesBySelectionMap.html" class="code" title="function [dataset, data2D] = selectFeaturesBySelectionMap(dataset)">selectFeaturesBySelectionMap</a>(ds);
0269   <span class="keyword">elseif</span>(isfield(ds,<span class="string">'mask'</span>) &amp;&amp; ~isempty(ds.mask))      
0270     ds = <a href="setDataset_featureSelectionMap_ByMatrix.html" class="code" title="function [dataset] = setDataset_featureSelectionMap_ByMatrix(dataset, mapMatrix)">setDataset_featureSelectionMap_ByMatrix</a>(ds, ds.mask);
0271     [ds, maskedData2D] = <a href="selectFeaturesBySelectionMap.html" class="code" title="function [dataset, data2D] = selectFeaturesBySelectionMap(dataset)">selectFeaturesBySelectionMap</a>(ds);
0272   <span class="keyword">else</span>
0273     ds = <a href="setDataset_featureSelectionMap_ByMatrix.html" class="code" title="function [dataset] = setDataset_featureSelectionMap_ByMatrix(dataset, mapMatrix)">setDataset_featureSelectionMap_ByMatrix</a>(ds, ones(sizeMaskedData2D(1)*sizeMaskedData2D(2)*sizeMaskedData2D(3), <span class="string">'uint8'</span>));
0274     sizeData = size(ds.data);
0275     maskedData2D = reshape(ds.data, sizeData(1)*sizeData(2)*sizeData(3), sizeData(4))';    
0276   <span class="keyword">end</span>
0277  
0278 <span class="keyword">end</span> <span class="comment">% end function  member_getMasked2DData_from4D</span>
0279 
0280 
0281 <a name="_sub2" href="#_subfunctions" class="code">function [ds, maskedData2D] = member_getMasked2DData_from2D(ds)</a>
0282   sizeMaskedData2D = size(ds.data);
0283      
0284   <span class="comment">%numel(find(dataset.featureSelectionMap1D &gt; 0)</span>
0285   <span class="comment">%get the data as 2D array by using the 1D mask1D</span>
0286   <span class="comment">%the function selectFeaturesBySelectionMap sets the field dataset.featureSelectionMap3D</span>
0287   <span class="keyword">if</span>(isfield(ds,<span class="string">'featureSelectionMap'</span>) &amp;&amp; ~isempty(ds.featureSelectionMap))
0288     [ds, maskedData2D] = <a href="selectFeaturesBySelectionMap.html" class="code" title="function [dataset, data2D] = selectFeaturesBySelectionMap(dataset)">selectFeaturesBySelectionMap</a>(ds);
0289   <span class="keyword">elseif</span>(isfield(ds,<span class="string">'mask'</span>) &amp;&amp; ~isempty(ds.mask))      
0290     ds = <a href="setDataset_featureSelectionMap_ByMatrix.html" class="code" title="function [dataset] = setDataset_featureSelectionMap_ByMatrix(dataset, mapMatrix)">setDataset_featureSelectionMap_ByMatrix</a>(ds, ds.mask);
0291     [ds, maskedData2D] = <a href="selectFeaturesBySelectionMap.html" class="code" title="function [dataset, data2D] = selectFeaturesBySelectionMap(dataset)">selectFeaturesBySelectionMap</a>(ds);
0292   <span class="keyword">else</span>
0293     ds = <a href="setDataset_featureSelectionMap_ByMatrix.html" class="code" title="function [dataset] = setDataset_featureSelectionMap_ByMatrix(dataset, mapMatrix)">setDataset_featureSelectionMap_ByMatrix</a>(ds, ones(sizeMaskedData2D(1),1, <span class="string">'uint8'</span>));
0294     maskedData2D = ds.data';
0295   <span class="keyword">end</span>
0296 
0297 <span class="keyword">end</span> <span class="comment">% end function  member_getMasked2DData_from2D</span></pre></div>
<hr><address>Generated on Mon 22-Oct-2012 13:45:25 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>